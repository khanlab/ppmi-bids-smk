# -*- coding: utf-8 -*-
"""
This script serves as a heuristic for use with HeuDiConv in converting PPMI
data into BIDS format.
"""

import os
import logging

lgr = logging.getLogger(__name__)
scaninfo_suffix = '.json'


def create_key(template, outtype=('nii.gz',), annotation_classes=None):
    if template is None or not template:
        raise ValueError('Template must be a valid format string')
    return template, outtype, annotation_classes


def infotodict(seqinfo):
    """
    Heuristic evaluator for determining which runs belong where

    allowed template fields - follow python string module:

    item: index within category
    subject: participant id
    seqitem: run number during scanning
    subindex: sub index within group
    """

    # {bids_subject_session_dir} : "sub-X/ses-Y"
    # {bids_subject_session_prefix} : "sub-X_ses-Y"
    t1w = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_T1w')  # noqa
    t2w = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_T2w')  # noqa
    t2starw = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_T2starw')  # noqa
    pd = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_PDw')  # noqa
    mtw = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_MTw')  # noqa
    pdt2 = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_PDT2')  # noqa
    flair = create_key('{bids_subject_session_dir}/anat/{bids_subject_session_prefix}_run-{item:02d}_FLAIR')  # noqa
    bold = create_key('{bids_subject_session_dir}/func/{bids_subject_session_prefix}_task-rest_run-{item:02d}_bold')  # noqa
    dti = create_key('{bids_subject_session_dir}/dwi/{bids_subject_session_prefix}_run-{item:02d}_dwi')  # noqa

    info = {t1w: [], mtw: [], t2starw: [],
            t2w: [], pd: [], pdt2: [], flair: [], bold: [], dti: []}

    for s in seqinfo:
        seql = s.series_description.lower()

        if ('t1' in seql) or ('mprage' in seql) or ('spgr' in seql) or ('bravo' in seql) or ('mpr' in seql and 'sag' in seql):
            info[t1w].append(s.series_id)
        elif ('dti' in seql) or ('diff' in seql) or ('gated' in seql) or ('dwi' in seql):
            info[dti].append(s.series_id)
#        elif 'flair' in seql:
#            info[flair].append(s.series_id)
#        elif ('rs' in seql) or ('resting' in seql):
#            info[bold].append(s.series_id)
#        elif ('nm' in seql) or ('mt' in seql):
#            info[mtw].append(s.series_id)
#        elif ('pd' in seql) or ('dual' in seql):
#            if s.dim3 < 40:
#                info[t2w].append(s.series_id)
#            else:
#                info[pdt2].append(s.series_id)
#        elif 't2' in seql:
#            info[t2w].append(s.series_id)
#        elif ('swan' in seql) or ('*' in seql):
#            info[t2starw].append(s.series_id)
        else:
            lgr.warning('Skipping unrecognized series description: {}'
                        .format(s.series_description))


    return info


def custom_callable(*args):
    """
    Called at the end of `heudiconv.convert.convert()` to perform clean-up

    Checks to see if multiple "clean" output files were generated by
    ``heudiconv``. If so, assumes that this was because they had different echo
    times and tries to rename them and embed metadata from the relevant dicom
    files. This only needs to be done because the PPMI dicoms are a hot mess
    (cf. all the lists above with different series descriptions).
    """

    import glob
    import re
    import pydicom as dcm
    import nibabel as nib
    import numpy as np
    from heudiconv.cli.run import get_parser
    from heudiconv.dicoms import embed_metadata_from_dicoms
    from heudiconv.utils import (
        load_json,
        TempDirs,
        treat_infofile,
        set_readonly
    )

    # unpack inputs and get command line arguments (again)
    # there's gotta be a better way to do this, but c'est la vie
    prefix, outtypes, item_dicoms = args[:3]
    outtype = outtypes[0]
#    opts = get_parser().parse_args()

    # if you don't want BIDS format then you're going to have to rename outputs
    # on your own!
#    if not opts.bids:
#        return

    # do a crappy job of checking if multiple output files were generated
    # if we're only seeing one file, we're good to go
    # otherwise, we need to do some fun re-naming...
    res_files = glob.glob(prefix + '[1-9].' + outtype)
    if len(res_files) < 2:
        return

    # there are few a sequences with some weird stuff that causes >2
    # files to be generated, some of which are two-dimensional (one slice)
    # we don't want that because that's nonsense, so let's design a check
    # for 2D files and just remove them
    for fname in res_files:
        if len([f for f in nib.load(fname).shape if f > 1]) < 3:
            os.remove(fname)
            os.remove(fname.replace(outtype, 'json'))
    res_files = [fname for fname in res_files if os.path.exists(fname)]
    bids_pairs = [(f, f.replace(outtype, 'json')) for f in res_files]

    # if there's only one file remaining don't add a needless 'echo' key
    # just rename the file and be done with it
    if len(bids_pairs) == 1:
        safe_movefile(bids_pairs[0][0], prefix + '.' + outtype)
        safe_movefile(bids_pairs[0][1], prefix + scaninfo_suffix)
        return

    # usually, at least two remaining files will exist
    # the main reason this happens with PPMI data is dual-echo sequences
    # look in the json files for EchoTime and generate a key based on that
    echonums = [load_json(json).get('EchoTime') for (_, json) in bids_pairs]
    if all([f is None for f in echonums]):
        return
    echonums = np.argsort(echonums) + 1

    for echo, (nifti, json) in zip(echonums, bids_pairs):
        # create new prefix with echo specifier
        # this isn't *technically* BIDS compliant, yet, but we're making due...
        split = re.search(r'run-(\d+)_', prefix).end()
        new_prefix = (prefix[:split]
                      + 'echo-%d_' % echo
                      + prefix[split:])
        outname, scaninfo = (new_prefix + '.' + outtype,
                             new_prefix + scaninfo_suffix)

        # safely move files to new name
        safe_movefile(nifti, outname, overwrite=False)
        safe_movefile(json, scaninfo, overwrite=False)

        # embed metadata from relevant dicoms (i.e., with same echo number)
        dicoms = [f for f in item_dicoms if
                  isclose(float(dcm.read_file(f, force=True).EchoTime) / 1000,
                          load_json(scaninfo).get('EchoTime'))]
#        prov_file = prefix + '_prov.ttl' if opts.with_prov else None
#        embed_metadata_from_dicoms(opts.bids, dicoms,
#                                   outname, new_prefix + '.json',
#                                   prov_file, scaninfo, TempDirs(),
#                                   opts.with_prov, opts.minmeta)

        # perform the bits of heudiconv.convert.convert that were never called
        if scaninfo and os.path.exists(scaninfo):
            lgr.info("Post-treating %s file", scaninfo)
            treat_infofile(scaninfo)
        if outname and os.path.exists(outname):
            set_readonly(outname)

        # huzzah! great success if you've reached this point


def isclose(a, b, rel_tol=1e-06, abs_tol=0.0):
    """
    Determine whether two floating point numbers are close in value.

    Literally just math.isclose() from Python >3.5 as defined in PEP 485

    Parameters
    ----------
    a, b, : float
        Floats to compare
    rel_tol : float
       Maximum difference for being considered "close", relative to the
       magnitude of the input values
    abs_tol : float
       Maximum difference for being considered "close", regardless of the
       magnitude of the input values

    Returns
    -------
    bool
        True if `a` is close in value to `b`, and False otherwise.

    For the values to be considered close, the difference between them must be
    smaller than at least one of the tolerances.
    """

    return abs(a - b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)


def safe_movefile(src, dest, overwrite=False):
    """
    Safely move `source` to `dest`, avoiding overwriting unless `overwrite`

    Uses `heudiconv.utils.safe_copyfile` before calling `os.remove` on `src`

    Parameters
    ----------
    src : str
        Path to source file; will be removed
    dest : str
        Path to dest file; should not exist
    overwrite : bool
        Whether to overwrite destination file, if it exists
    """

    from heudiconv.utils import safe_copyfile

    try:
        safe_copyfile(src, dest, overwrite)
        os.remove(src)
    except RuntimeError:
        lgr.warning('Tried moving %s to %s but %s ' % (src, dest, dest)
                    + 'already exists?! Check your outputs to make sure they '
                    + 'look okay...')
